---
prometheus_external_labels:
  region: us-california-1
  monitor: satstack-homelab
  replica: 1

# prometheus_targets is just a map used to create multiple files located in "{{ prometheus_config_dir }}/file_sd" directory.
# Where file names are composed from top-level keys in that map with .yml suffix. Those files store file_sd scrape targets 
# data and they need to be read in prometheus_scrape_configs.
prometheus_targets:
  node:
  # - targets:
  #     - shinx.charlgiwnbro.com:4430
  #   labels:
  #     group: charlgiwnbro

    - targets:
#       - charmander.brenise.com:4430
        - incineroar.brenise.com:4430
      labels:
        group: brenise

    - targets:
        - charmander.satstack.net:4430
        - chespin.satstack.net:4430
        - wartortle.satstack.net:4430
        - squirtle.satstack.net:4430
        - omastar.satstack.net:4430
      labels:
        group: satstack

# another important note about file_sd targets (above) is that they are periodically refreshed by prometheus, but the rest of the config (below) is not.
prometheus_scrape_configs:
  - job_name: prometheus
    scheme: https
    metrics_path: /prometheus/metrics
    static_configs:
      - targets:
          - "{{ inventory_hostname }}"
          - "{{ lookup('ansible.builtin.env', 'testnet_prometheus') }}"
#         - "{{ lookup('ansible.builtin.env', 'work_prometheus') }}" # TODO: fix routing

# - job_name: snmp
#   static_configs:
#     - targets:
#       - 192.168.0.1
#   metrics_path: /snmp
#   params:
#     auth: [public_v2]
#     module: [if_mib]
#   relabel_configs:
#     - source_labels: [__address__]
#       target_label: __param_target
#     - source_labels: [__param_target]
#       target_label: instance
#     - target_label: __address__
#       replacement: 192.168.0.43:9116  # The SNMP exporter's real hostname:port.

  - job_name: node
    scheme: https
    file_sd_configs:
      - files:
          - "{{ prometheus_config_dir }}/file_sd/node.yml"

  - job_name: nodehttp
    static_configs:
      - targets:
        - shinx.brenise.com:9100
#       - rotom.satstack.net:9100

# - job_name: lnd
#   scheme: https
#   static_configs:
#     - targets:
#       - squirtle.satstack.net:9101

# broken https://github.com/lightningd/plugins/pull/451
  - job_name: lightning
    scheme: https
    scrape_interval: 2m
    static_configs:
      - targets:
        - squirtle.satstack.net:9105
        labels:
          group: lightningd
      - targets:
        - squirtle.satstack.net:9109
        labels:
          group: lnd

  - job_name: electrum
    scheme: https
    scrape_interval: 2m
    static_configs:
      - targets:
        - chespin.satstack.net:4432

  - job_name: testnet
    scheme: https
    scrape_interval: 30s
    static_configs:
      - targets:
        - wartortle.satstack.net:4444

  - job_name: miniflux
    scheme: https
    static_configs:
      - targets:
        - chespin.satstack.net:4431

  - job_name: samourai-dojo
    scheme: https
    static_configs:
      - targets:
        - wartortle.satstack.net:4442

  - job_name: health-checks
    scheme: https
    scrape_interval: 2m
    metrics_path: /probe
    params:
      module: [http_2xx]
    static_configs:
      - targets:
        - https://matrix.brenise.com/health
#       - https://blee.tube/api/v1/videos
        - https://chespin.satstack.net:4439/api/mempool
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: "{{ inventory_hostname }}:4431"

prometheus_alert_rules:
  - alert: Prometheus
    expr: up{job="prometheus"} == 0
    for: 2h
    annotations:
      summary: Prometheus has not responded for at least a couple hours.
      description: Check metrics exported directly from the main prometheus daemon.

  - alert: High compute utilization alert
    expr: avg by (instance) (irate(node_cpu_seconds_total{job="nodes",mode="idle"}[5m])) < 0.6
    for: 5m
    annotations:
      summary: Elevated compute utilization.

  - alert: High disk storage utilization alert
    expr: 100 - ((node_filesystem_avail_bytes{job="nodes",mountpoint="/",fstype!="rootfs"} * 100) / node_filesystem_size_bytes{job="nodes",mountpoint="/",fstype!="rootfs"}) > 80
    for: 1h
    annotations:
      summary: Server is running low on available disk space.

  - alert: Health checks
    expr: probe_success{job="health-checks"} == 0
    for: 15m
    annotations:
      summary: A health-check has failed.

# - alert: bitcoind offline
#   expr: up{job="bitcoind"} == 0
#   for: 30m
#   annotations:
#     summary: bitcoind is responding

  - alert: electrs offline
    expr: up{job="electrum"} == 0
    for: 15m
    annotations:
      summary: electrs is not responding

  - alert: Lightning daemon offline (lnd or lightningd)
    expr: up{job="lightning"} == 0
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: Lightning daemon is not running.

  - alert: Lightning Peer Offline
    expr: lightning_peer_connected == 0
    for: 12h
    labels:
      severity: warning
    annotations:
      summary: "A lightning peer has been offline for more than 12 hours."

# - alert: LND Monitor
#   expr: lnd_channels_inactive_total{job="lndmon"} / lnd_channels_active_total{job="lndmon"} > 0.5
#   for: 15m 
#   annotations:
#     summary: Most lightning channels are inactive. Check LND and Tor.

  - alert: samourai dojo offline
    expr: probe_success{job="samourai-dojo"} == 0
    for: 15m
    annotations:
      summary: samourai dojo is not running.

  - alert: Stale Samourai Dojo block height
#   expr: min(dojo_block_height) < max(bitcoin_latest_block_height)
    expr: dojo_block_height < dojo_indexer_max_height
    for: 1h
    annotations:
      summary: Node has fewer blocks than peers, possibly indicating an outage.
      description: Dojo shows stale blocks. You should probably check on bitcoind, and then restart Samourai Dojo.

  - alert: Dojo shows stale indexer tip height
#   expr: dojo_indexer_max_height < max(bitcoin_latest_block_height)
    expr: dojo_indexer_max_height < dojo_block_height
    for: 1h
    annotations:
      summary: Dojo is not longer seeing up block updates from electrs.
      description: Dojo shows the indexer with an lower (stale) block height. It could mean there is a problem with the indexer, or it could be a connectivity problem where the Dojo is unable to reach the ZMQ ports on bitcoind.

# - alert: Stale lightningd block height
#   expr: lightning_node_blockheight < max(bitcoin_latest_block_height)
#   for: 1h
#   annotations:
#     summary: Dojo indicates that the electrum server appears to have stalled or crashed.
#     description: Check electrs and dojo logs. Restart if necessary.

# - alert: LND uptime
#   expr: up{job="lnd"} == 0
#   for: 5m
#   annotations:
#     summary: LND is not running.
